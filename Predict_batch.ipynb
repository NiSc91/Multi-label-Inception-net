{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #1 Predicts probabilities of each label for a batch of images\n",
    "See output and header info below\n",
    "\n",
    "## #2 Converts prediction file with probabilities to predicted true labels (Kaggle iMaterialist format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 1.7.0\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from PIL import Image, ImageOps\n",
    "import os, sys\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1445.5216188430786\n"
     ]
    }
   ],
   "source": [
    "#1 Predict probabilities for labels, save .csv\n",
    "\n",
    "#Runtime 109s for 100 (155kB, with .4 float precision, on Intel i7), 1445s for 1000 imgs (1.6MB)\n",
    "\n",
    "#params\n",
    "input_path = 'validation256/'\n",
    "first = 1\n",
    "last = 1000\n",
    "image_numbers = range(first, last+1)\n",
    "save_path = 'predictions/'\n",
    "save_as = 'predicted_v1000.csv'\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "#modified from https://github.com/BartyzalRadek/Multi-label-Inception-net\n",
    "# Loads label file, strips off carriage return\n",
    "label_lines = [line.rstrip() for line \n",
    "                   in tf.gfile.GFile(\"labels.txt\")]\n",
    "top_k = np.asarray([int(lbl) for lbl in label_lines])\n",
    "\n",
    "all_predictions = np.empty([len(image_numbers),len(label_lines)+1])\n",
    "\n",
    "# Unpersists graph from file\n",
    "with tf.gfile.FastGFile(\"retrained_graph.pb\", 'rb') as f:\n",
    "    graph_def = tf.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())\n",
    "    _ = tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "\n",
    "#iterate over images\n",
    "counter = 0\n",
    "for i, image_num in enumerate(image_numbers):\n",
    "    image_path = input_path+str(image_num)+'.jpg'\n",
    "    #print(image_path)\n",
    "    # Read in the image_data\n",
    "    image_data = tf.gfile.FastGFile(image_path, 'rb').read()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        # Feed the image_data as input to the graph and get first prediction\n",
    "        softmax_tensor = sess.graph.get_tensor_by_name('final_result:0')\n",
    "\n",
    "        predictions = sess.run(softmax_tensor, \\\n",
    "                 {'DecodeJpeg/contents:0': image_data})\n",
    "\n",
    "    all_predictions[i] = np.insert(predictions, 0, image_num)\n",
    "    \n",
    "    if (counter == 1000):\n",
    "        print(image_num)\n",
    "        np.savetxt(save_path+save_as, all_predictions, delimiter=\",\", fmt='%1.4f')\n",
    "        counter = 0\n",
    "        \n",
    "    counter += 1\n",
    "\n",
    "np.savetxt(save_path+save_as, all_predictions, delimiter=\",\", fmt='%1.4f')\n",
    "\n",
    "#header\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "print('Saved to '+save_path+save_as)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to predictions/predicted_v1000.csv.head\n",
      "['image', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '157', '158', '159', '160', '161', '162', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189', '190', '191', '192', '193', '195', '196', '197', '198', '199', '200', '201', '202', '203', '204', '205', '206', '207', '208', '209', '210', '211', '212', '213', '214', '215', '216', '217', '218', '219', '220', '221', '222', '223', '224', '225', '226', '227', '228']\n"
     ]
    }
   ],
   "source": [
    "#header:\n",
    "#image_num, labels separated by commas, sourced from labels.txt (generated in preprocessing)\n",
    "header=[lbl for lbl in label_lines]\n",
    "header.insert(0,'image')\n",
    "with open(save_path+save_as+'.head', 'w') as headfile:\n",
    "    wr = csv.writer(headfile)\n",
    "    wr.writerow(header)\n",
    "print('Saved to '+save_path+save_as+'.head')\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  0.17220522,  0.17524981,  0.17121118,  0.16985664,\n",
       "        0.17000282,  0.16917139,  0.17647776,  0.16882296,  0.17106469,\n",
       "        0.16800098,  0.17487083,  0.16953056,  0.17390741,  0.1758121 ,\n",
       "        0.17792206,  0.29614499,  0.19244042,  0.2207858 ,  0.22344185,\n",
       "        0.17249553,  0.17033365,  0.16778883,  0.16925192,  0.17555028,\n",
       "        0.1703099 ,  0.1683688 ,  0.17517875,  0.16967089,  0.16830975,\n",
       "        0.16876042,  0.17639604,  0.16827677,  0.16674174,  0.1720027 ,\n",
       "        0.20024487,  0.17230676,  0.17561071,  0.17264313,  0.17023093,\n",
       "        0.17080215,  0.16964871,  0.20744066,  0.17268752,  0.16641204,\n",
       "        0.17331682,  0.17044078,  0.20116149,  0.16867325,  0.17390676,\n",
       "        0.17427619,  0.23013963,  0.16984232,  0.17299178,  0.17015721,\n",
       "        0.17070986,  0.16621698,  0.1890462 ,  0.16809623,  0.18436661,\n",
       "        0.2466597 ,  0.17446767,  0.17390631,  0.17478429,  0.69878429,\n",
       "        0.16992924,  0.16417791,  0.17368294,  0.18907806,  0.16962576,\n",
       "        0.17001157,  0.19331336,  0.17919287,  0.17435603,  0.16968885,\n",
       "        0.17216973,  0.19057357,  0.19312289,  0.16797251,  0.17001124,\n",
       "        0.17482021,  0.16908832,  0.16985211,  0.17012388,  0.16879143,\n",
       "        0.18707725,  0.18052495,  0.16832285,  0.169074  ,  0.19127116,\n",
       "        0.17107806,  0.16884287,  0.1717827 ,  0.17022794,  0.18656482,\n",
       "        0.22288911,  0.18317786,  0.18044293,  0.17146972,  0.17035644,\n",
       "        0.17893606,  0.16663165,  0.43830594,  0.27107158,  0.16523562,\n",
       "        0.16704746,  0.16961507,  0.19043449,  0.17463048,  0.16916184,\n",
       "        0.19414347,  0.17443776,  0.1813224 ,  0.18281649,  0.17599359,\n",
       "        0.1683328 ,  0.17309946,  0.16800882,  0.1731288 ,  0.1872388 ,\n",
       "        0.16765879,  0.16974005,  0.16921584,  0.17243154,  0.17032038,\n",
       "        0.1866824 ,  0.16930832,  0.17134689,  0.19074836,  0.17389968,\n",
       "        0.19056387,  0.16805804,  0.17761171,  0.17009854,  0.22393182,\n",
       "        0.24140035,  0.16961209,  0.17042026,  0.169736  ,  0.18238655,\n",
       "        0.17395936,  0.17789866,  0.17112124,  0.17090483,  0.21489291,\n",
       "        0.16788422,  0.17242253,  0.18156482,  0.16797751,  0.35443917,\n",
       "        0.17867675,  0.17645726,  0.16548073,  0.1719107 ,  0.17463297,\n",
       "        0.16624483,  0.1632863 ,  0.16786318,  0.21620931,  0.17378479,\n",
       "        0.18154907,  0.17328225,  0.17065896,  0.1701327 ,  0.1815481 ,\n",
       "        0.28652722,  0.16960812,  0.16942185,  0.16699928,  0.18859179,\n",
       "        0.21310574,  0.16854991,  0.17346637,  0.16869204,  0.18137048,\n",
       "        0.17623357,  0.16801353,  0.18267789,  0.19591433,  0.17007495,\n",
       "        0.19348726,  0.16805156,  0.1707194 ,  0.17894599,  0.17965771,\n",
       "        0.16488853,  0.17006767,  0.17638013,  0.16818331,  0.16928326,\n",
       "        0.17077993,  0.16852751,  0.16891386,  0.17296381,  0.17034116,\n",
       "        0.16821285,  0.16991238,  0.18596295,  0.18619835,  0.17039031,\n",
       "        0.16701698,  0.1651157 ,  0.17259526,  0.16915786,  0.17291951,\n",
       "        0.17404959,  0.17116003,  0.26919475,  0.16663538,  0.16970481,\n",
       "        0.17434102,  0.18603711,  0.1664044 ,  0.17001203,  0.16980304,\n",
       "        0.23993219,  0.17232287,  0.17841098,  0.17669713,  0.18453556,\n",
       "        0.17088704,  0.16701017])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example entry for 1 image:\n",
    "all_predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#iMaterialist sample submission format:\n",
    "image_id,label_id\n",
    "1,106 115 126 145 161 176 185 32\n",
    "2,115 13 14 158 18 184 190 220 227 44 47 56 81 9 92\n",
    "3,104 112 129 224 31 83\n",
    "4,113 121 145 150 218 63 77\n",
    "5,1 126 167 170 196 208 213 216 22 32 48 54 79"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28173303604125977\n",
      "Saved to predictions/final_0.35_predicted_v1000.csv\n"
     ]
    }
   ],
   "source": [
    "#2 Read label probabilities .csv and corresponding headers (.head), select true labels by thresholding, save in competition-required format\n",
    "#Runtime 0.3s for 1000\n",
    "\n",
    "#params\n",
    "threshold = 0.35\n",
    "\n",
    "input_prob_path = 'predictions/'\n",
    "input_prob = 'predicted_v1000.csv'\n",
    "save_path = 'predictions/'\n",
    "save_as = 'final_'+str(threshold)+'_'+input_prob\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "probdf = pd.read_csv(input_prob_path+input_prob, header=None)\n",
    "probdf.columns=pd.read_csv(input_prob_path+input_prob+'.head', header=None).values.tolist()\n",
    "probdf['image'] = probdf['image'].astype(int)\n",
    "\n",
    "with open(save_path+save_as, \"w\") as final_labels:\n",
    "    final_labels.write('image_id,label_id'+'\\n')\n",
    "    for ri, row in probdf.iterrows():\n",
    "        image_labels = str(int(row[0]))+','\n",
    "        for ci, col in enumerate(row[1:]):\n",
    "            if col >= threshold:\n",
    "                image_labels = image_labels+str(int(probdf.columns[ci+1][0]))+' '\n",
    "        final_labels.write(image_labels[:-1]+'\\n')\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "print('Saved to '+save_path+save_as)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
